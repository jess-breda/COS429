{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path += ['layers']\n",
    "import numpy as np\n",
    "from init_layers import init_layers\n",
    "from init_model import init_model\n",
    "from inference import inference\n",
    "from loss_euclidean import loss_euclidean\n",
    "from data_utils import get_CIFAR10_data\n",
    "\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "use_pcode = True\n",
    "if use_pcode:\n",
    "    # import the provided pyc implementation\n",
    "    sys.path += ['pyc_code']\n",
    "    from inference_ import inference\n",
    "    from calc_gradient_ import calc_gradient\n",
    "    from update_weights_ import update_weights\n",
    "else:\n",
    "    # import your own implementation\n",
    "    from inference import inference\n",
    "    from calc_gradient import calc_gradient\n",
    "    from update_weights import update_weights\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape:  (32, 32, 3, 50000)\n",
      "Train labels shape:  (50000,)\n",
      "Test data shape:  (32, 32, 3, 10000)\n",
      "Test labels shape:  (10000,)\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test = get_CIFAR10_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = 1\n",
    "plt.imshow(X_train[:,:,:,img])\n",
    "print(y_train[img])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simple example with linear function. Note shapes aren't correct to do backprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fn_linear_ import fn_linear\n",
    "linear = init_layers(\"linear\", {\"num_in\": 32, \"num_out\": 10})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['fwd_fn', 'type', 'params', 'hyper_params'])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function fn_linear_.fn_linear(input, params, hyper_params, backprop, dv_output=None)>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear['fwd_fn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_in': 32, 'num_out': 10}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear['hyper_params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.randn(32,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 1)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W = linear['params']['W'].shape\n",
    "b = linear['params']['b'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 10, 1)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = linear['params']['W'] @ x + linear['params']['b']\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.05682721],\n",
       "        [-0.31463083],\n",
       "        [ 1.17901568],\n",
       "        [-0.2993785 ],\n",
       "        [ 0.11107539],\n",
       "        [-0.65765187],\n",
       "        [ 0.08772662],\n",
       "        [-0.62991493],\n",
       "        [-1.04966365],\n",
       "        [ 0.6350179 ]]),\n",
       " array([], dtype=float64),\n",
       " {'W': array([], dtype=float64), 'b': array([], dtype=float64)})"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear['fwd_fn'](x, linear['params'], linear['hyper_params'],backprop=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing a model\n",
    "\n",
    "Basic size and content information can be seen below for each layer in the model. When the layer is initialized, the weights are also initialized for that layer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [\n",
    "    init_layers(\"conv\", {\"filter_size\": 2, \"filter_depth\": 3, \"num_filters\": 2}),\n",
    "    init_layers(\"pool\", {\"filter_size\": 2, \"stride\": 2}),\n",
    "    init_layers(\"relu\", {}),\n",
    "    init_layers(\"flatten\", {}),\n",
    "    init_layers(\"linear\", {\"num_in\": 32, \"num_out\": 10}),\n",
    "    init_layers(\"softmax\", {}),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['fwd_fn', 'type', 'params', 'hyper_params'])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer type: conv\n",
      "layer type: pool\n",
      "layer type: relu\n",
      "layer type: flatten\n",
      "layer type: linear\n",
      "layer type: softmax\n"
     ]
    }
   ],
   "source": [
    "for layer in l:\n",
    "    print(f\"layer type: {layer['type']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer type: <function fn_conv at 0x000002D8BBA638B8>\n",
      "layer type: <function fn_pool at 0x000002D8AC7433A8>\n",
      "layer type: <function fn_relu at 0x000002D8AC733D38>\n",
      "layer type: <function fn_flatten at 0x000002D89E2A4318>\n",
      "layer type: <function fn_linear at 0x000002D8AC87EEE8>\n",
      "layer type: <function fn_softmax at 0x000002D8AC802F78>\n"
     ]
    }
   ],
   "source": [
    "for layer in l:\n",
    "    print(f\"layer type: {layer['fwd_fn']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer params: dict_keys(['W', 'b'])\n",
      "layer params: dict_keys(['W', 'b'])\n",
      "layer params: dict_keys(['W', 'b'])\n",
      "layer params: dict_keys(['W', 'b'])\n",
      "layer params: dict_keys(['W', 'b'])\n",
      "layer params: dict_keys(['W', 'b'])\n"
     ]
    }
   ],
   "source": [
    "for layer in l:\n",
    "    print(f\"layer params: {layer['params'].keys()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer params: dict_keys(['filter_size', 'filter_depth', 'num_filters'])\n",
      "layer params: dict_keys(['filter_size', 'stride'])\n",
      "layer params: dict_keys([])\n",
      "layer params: dict_keys([])\n",
      "layer params: dict_keys(['num_in', 'num_out'])\n",
      "layer params: dict_keys([])\n"
     ]
    }
   ],
   "source": [
    "for layer in l:\n",
    "    print(f\"layer params: {layer['hyper_params'].keys()}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets initialize a model with these layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input size:\n",
      "[10, 10, 3]\n",
      "Layer 0 output size: \n",
      "(9, 9, 2)\n",
      "Layer 1 output size: \n",
      "(4, 4, 2)\n",
      "Layer 2 output size: \n",
      "(4, 4, 2)\n",
      "Layer 3 output size: \n",
      "(32,)\n",
      "Layer 4 output size: \n",
      "(10,)\n",
      "Final output size:\n",
      "(10,)\n",
      "Provided output size (should match above):\n",
      "10\n",
      "(Batch dimension not included)\n"
     ]
    }
   ],
   "source": [
    "model = init_model(\n",
    "    layers=l,\n",
    "    input_size=[10,10,3], # does not include batches only [H,W,D] \n",
    "    output_size=10, \n",
    "    display=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['layers', 'input_size', 'output_size'])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer 0 dict: dict_keys(['fwd_fn', 'type', 'params', 'hyper_params'])\n",
      "input size: [10, 10, 3]\n",
      "output size: 10\n"
     ]
    }
   ],
   "source": [
    "layer_n = 0\n",
    "print(f\"layer {layer_n} dict: {model['layers'][layer_n].keys()}\")\n",
    "print(f\"input size: {model['input_size']}\")\n",
    "print(f\"output size: {model['output_size']}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Inference (Forward pass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "                 # [H, W, Channels, Batch]\n",
    "inp = np.random.rand(10, 10, 3, 4)  # Dummy input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "output, activations = inference(model, inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output size: (10, 4)\n",
      "layer 0 activation shape (9, 9, 2, 4)\n",
      "layer 1 activation shape (4, 4, 2, 4)\n",
      "layer 2 activation shape (4, 4, 2, 4)\n",
      "layer 3 activation shape (32, 4)\n",
      "layer 4 activation shape (10, 4)\n",
      "layer 5 activation shape (10, 4)\n"
     ]
    }
   ],
   "source": [
    "print(f\"output size: {output.shape}\")\n",
    "\n",
    "for ilayer, act in enumerate(activations):\n",
    "    print(f\"layer {ilayer} activation shape {act.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate loss"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stopping here- need to think about how to calcuate loss across a batch wrt to averaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 4)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calc_gradient(model, inp, activations,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cos429_A3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
